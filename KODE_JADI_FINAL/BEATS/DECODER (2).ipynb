{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fa89996-7f03-43d4-9139-e43a23603319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre-encoding: 100%|██████████| 28000/28000 [00:03<00:00, 7486.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== FOLD 1/5 ====\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.58 GiB of which 16.44 MiB is free. Process 71901 has 10.64 GiB memory in use. Process 236872 has 8.58 GiB memory in use. Process 309636 has 4.33 GiB memory in use. Of the allocated memory 4.02 GiB is allocated by PyTorch, and 15.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 91\u001b[0m\n\u001b[1;32m     88\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_ds, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     89\u001b[0m val_loader   \u001b[38;5;241m=\u001b[39m DataLoader(val_ds,   batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE)\n\u001b[0;32m---> 91\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mDecoderOnlyClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m optim \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mLR)\n\u001b[1;32m     93\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mCosineAnnealingLR(optim, EPOCHS)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 810 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.58 GiB of which 16.44 MiB is free. Process 71901 has 10.64 GiB memory in use. Process 236872 has 8.58 GiB memory in use. Process 309636 has 4.33 GiB memory in use. Of the allocated memory 4.02 GiB is allocated by PyTorch, and 15.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import os, glob, gc, copy, math, random, time, json\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ══════════════════════════ KONFIGURASI ══════════════════════════\n",
    "DATA_DIR    = \"/workspace/SPLIT_BEATS_NPY/train\"\n",
    "LABEL_MAP   = {'N':0,'L':1,'R':2,'V':3,'Q':4}\n",
    "SEED        = 42\n",
    "N_SPLITS    = 5\n",
    "EPOCHS      = 1\n",
    "BATCH_SIZE  = 16\n",
    "MAX_LEN     = 512\n",
    "EMB_DIM     = 512\n",
    "N_HEADS     = 8\n",
    "FF_DIM      = 2048\n",
    "N_LAYERS    = 12\n",
    "LR          = 2e-5\n",
    "OUTPUT_BASE = \"/workspace/HASIL_DECODER/HASIL_1\"\n",
    "os.makedirs(OUTPUT_BASE, exist_ok=True)\n",
    "\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "PAD_ID, CLS_ID  = 256, 257\n",
    "VOCAB_SIZE      = 258\n",
    "cls_names       = list(LABEL_MAP.keys())\n",
    "\n",
    "# ══════════ UTILITAS ══════════\n",
    "\n",
    "def signal_to_ids(sig: np.ndarray):\n",
    "    norm = ((sig - sig.min()) / (sig.ptp() + 1e-8) * 255).astype(int)\n",
    "    ids  = np.concatenate(([CLS_ID], norm))[:MAX_LEN]\n",
    "    mask = np.ones_like(ids, dtype=int)\n",
    "    if len(ids) < MAX_LEN:\n",
    "        pad_len = MAX_LEN - len(ids)\n",
    "        ids  = np.concatenate((ids,  np.full(pad_len, PAD_ID)))\n",
    "        mask = np.concatenate((mask, np.zeros(pad_len)))\n",
    "    return ids, mask\n",
    "\n",
    "# ══════════ MUAT DATA ══════════\n",
    "files, labels = [], []\n",
    "for cls, idx in LABEL_MAP.items():\n",
    "    for f in glob.glob(os.path.join(DATA_DIR, cls, \"*.npy\")):\n",
    "        files.append(f); labels.append(idx)\n",
    "files, labels = np.array(files), np.array(labels)\n",
    "\n",
    "all_ids, all_mask = [], []\n",
    "for f in tqdm(files, desc=\"Pre-encoding\"):\n",
    "    ids, msk = signal_to_ids(np.load(f))\n",
    "    all_ids.append(ids);  all_mask.append(msk)\n",
    "all_ids  = torch.tensor(all_ids,  dtype=torch.long)\n",
    "all_mask = torch.tensor(all_mask, dtype=torch.long)\n",
    "labels_t = torch.tensor(labels,   dtype=torch.long)\n",
    "\n",
    "# ══════════ DEFINISI DECODER-ONLY ══════════\n",
    "class DecoderOnlyClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(VOCAB_SIZE, EMB_DIM, padding_idx=PAD_ID)\n",
    "        self.pos_emb   = nn.Parameter(torch.zeros(1, MAX_LEN, EMB_DIM))\n",
    "        dec_layer = nn.TransformerDecoderLayer(d_model=EMB_DIM, nhead=N_HEADS,\n",
    "                                               dim_feedforward=FF_DIM, dropout=0.1,\n",
    "                                               batch_first=True)\n",
    "        self.decoder = nn.TransformerDecoder(dec_layer, num_layers=N_LAYERS)\n",
    "        self.fc      = nn.Linear(EMB_DIM, len(LABEL_MAP))\n",
    "        nn.init.normal_(self.pos_emb, std=0.02)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        tgt = self.token_emb(input_ids) + self.pos_emb\n",
    "        memory = torch.zeros_like(tgt).to(tgt.device)  # dummy memory\n",
    "        x = self.decoder(tgt, memory, tgt_key_padding_mask=~attention_mask.bool())\n",
    "        x = (x * attention_mask.unsqueeze(-1)).sum(1) / attention_mask.sum(1, keepdim=True).clamp(min=1e-9)\n",
    "        return self.fc(x)\n",
    "\n",
    "# ══════════ K-FOLD TRAINING ══════════\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "rows_all = []\n",
    "\n",
    "for fold, (tr, va) in enumerate(skf.split(all_ids, labels), 1):\n",
    "    print(f\"\\n==== FOLD {fold}/{N_SPLITS} ====\")\n",
    "    gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "    train_ds = TensorDataset(all_ids[tr], all_mask[tr], labels_t[tr])\n",
    "    val_ds   = TensorDataset(all_ids[va], all_mask[va], labels_t[va])\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE)\n",
    "\n",
    "    model = DecoderOnlyClassifier().to(DEVICE)\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, EPOCHS)\n",
    "\n",
    "    best_state, best_loss = None, math.inf\n",
    "    out_dir = os.path.join(OUTPUT_BASE, f\"fold{fold}\"); os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        print(f\"\\U0001f552 Fold {fold} | Epoch {epoch}/{EPOCHS}\")\n",
    "        model.train(); total_loss = 0.0\n",
    "        for ids, msk, lbl in tqdm(train_loader, leave=False):\n",
    "            ids, msk, lbl = ids.to(DEVICE), msk.to(DEVICE), lbl.to(DEVICE)\n",
    "            optim.zero_grad(); out = model(ids, msk)\n",
    "            loss = F.cross_entropy(out, lbl)\n",
    "            loss.backward(); torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optim.step(); total_loss += loss.item()\n",
    "        scheduler.step()\n",
    "\n",
    "        model.eval(); val_loss, preds, yh = 0.0, [], []\n",
    "        with torch.no_grad():\n",
    "            for ids, msk, lbl in val_loader:\n",
    "                ids, msk, lbl = ids.to(DEVICE), msk.to(DEVICE), lbl.to(DEVICE)\n",
    "                out = model(ids, msk)\n",
    "                val_loss += F.cross_entropy(out, lbl, reduction='sum').item()\n",
    "                preds.append(out.argmax(1).cpu()); yh.append(lbl.cpu())\n",
    "        val_loss /= len(val_ds)\n",
    "        if val_loss < best_loss:\n",
    "            best_loss, best_state = val_loss, copy.deepcopy(model.state_dict())\n",
    "        print(f\"ValLoss={val_loss:.4f}\")\n",
    "\n",
    "    # Simpan model dan config\n",
    "    torch.save(best_state, os.path.join(out_dir, \"best_model.pt\"))\n",
    "    with open(os.path.join(out_dir, \"model_config.json\"), \"w\") as f:\n",
    "        json.dump({\"emb_dim\":EMB_DIM,\"n_layers\":N_LAYERS,\"n_heads\":N_HEADS,\"ff_dim\":FF_DIM,\n",
    "                   \"max_len\":MAX_LEN,\"vocab_size\":VOCAB_SIZE,\"pad_id\":PAD_ID,\"cls_id\":CLS_ID,\n",
    "                   \"label_map\":LABEL_MAP}, f, indent=2)\n",
    "    with open(os.path.join(out_dir, \"vocab.txt\"), \"w\") as f:\n",
    "        f.writelines([f\"{i}\\n\" for i in range(256)] + [\"[PAD]\\n\",\"[CLS]\\n\"])\n",
    "\n",
    "    # Evaluasi dan confusion matrix\n",
    "    model.load_state_dict(best_state); model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = []; y_true = []\n",
    "        for ids, msk, lbl in val_loader:\n",
    "            ids, msk = ids.to(DEVICE), msk.to(DEVICE)\n",
    "            logits.append(model(ids, msk).cpu()); y_true.append(lbl)\n",
    "    preds = torch.cat(logits).argmax(1).numpy(); y_true = torch.cat(y_true).numpy()\n",
    "\n",
    "    cm = confusion_matrix(y_true, preds, labels=list(range(len(cls_names))))\n",
    "    for i, cls in enumerate(cls_names):\n",
    "        TP = cm[i,i]; FN = cm[i].sum()-TP; FP = cm[:,i].sum()-TP; TN = cm.sum()-TP-FN-FP\n",
    "        ACC = (TP+TN)/cm.sum(); REC = TP/(TP+FN+1e-8)\n",
    "        SPEC = TN/(TN+FP+1e-8); F1 = 2*TP/(2*TP+FP+FN+1e-8)\n",
    "        rows_all.append({\"fold\":fold, \"kelas\":cls, \"akurasi\":round(ACC,4),\n",
    "                         \"f1\":round(F1,4), \"recall\":round(REC,4), \"spesifisitas\":round(SPEC,4)})\n",
    "\n",
    "    # Simpan confusion matrix gambar\n",
    "    plt.figure(figsize=(7,6)); plt.imshow(cm, cmap='Blues')\n",
    "    plt.title(f\"Confusion Fold {fold}\")\n",
    "    plt.xticks(range(len(cls_names)), cls_names)\n",
    "    plt.yticks(range(len(cls_names)), cls_names)\n",
    "    for r in range(len(cm)):\n",
    "        for c in range(len(cm)):\n",
    "            plt.text(c, r, cm[r,c], ha='center', va='center')\n",
    "    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_dir, \"confusion_fold.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# Simpan semua metrik\n",
    "pd.DataFrame(rows_all).to_csv(os.path.join(OUTPUT_BASE, \"final_summary_perkelas.csv\"), index=False)\n",
    "print(\"\\n✔️ Training selesai. Semua hasil disimpan.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
