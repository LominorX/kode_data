{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7d85cff-6d28-47af-a3a1-dcbe929561a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
      "Requirement already satisfied: transformers==4.48.2 in /usr/local/lib/python3.10/dist-packages (4.48.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.7.0)\n",
      "Requirement already satisfied: accelerate==0.26.0 in /usr/local/lib/python3.10/dist-packages (0.26.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.10.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.2) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.2) (0.33.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.2) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.2) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.2) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.2) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.2) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.2) (0.5.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.26.0) (5.9.6)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.2) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.2) (4.4.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.2) (1.1.4)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.48.2) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.48.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.48.2) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.48.2) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.26.4 torch transformers==4.48.2 scikit-learn accelerate==0.26.0 matplotlib tqdm pandas seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "720282af-88b9-4a99-a278-961bdba34ad6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preâ€‘encoding semua sampel â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28000/28000 [00:03<00:00, 8194.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â•â•â•â• FOLD 1/5 â•â•â•â•\n",
      "ðŸŒ€ Fold 1 | Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 1 | Epoch 1 done | TrainLoss=0.8875 | Time=261.4s\n",
      "ðŸ“Š  ValLoss=0.6863\n",
      "ðŸŒ€ Fold 1 | Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 1 | Epoch 2 done | TrainLoss=0.5396 | Time=261.6s\n",
      "ðŸ“Š  ValLoss=0.5823\n",
      "ðŸŒ€ Fold 1 | Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 1 | Epoch 3 done | TrainLoss=0.4140 | Time=261.7s\n",
      "ðŸ“Š  ValLoss=0.3920\n",
      "ðŸŒ€ Fold 1 | Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 1 | Epoch 4 done | TrainLoss=0.3407 | Time=261.3s\n",
      "ðŸ“Š  ValLoss=0.4125\n",
      "ðŸŒ€ Fold 1 | Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 1 | Epoch 5 done | TrainLoss=0.2934 | Time=261.4s\n",
      "ðŸ“Š  ValLoss=0.3479\n",
      "ðŸŒ€ Fold 1 | Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 1 | Epoch 6 done | TrainLoss=0.2582 | Time=261.4s\n",
      "ðŸ“Š  ValLoss=0.3550\n",
      "ðŸŒ€ Fold 1 | Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 1 | Epoch 7 done | TrainLoss=0.2210 | Time=261.4s\n",
      "ðŸ“Š  ValLoss=0.3040\n",
      "ðŸŒ€ Fold 1 | Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 1 | Epoch 8 done | TrainLoss=0.1981 | Time=260.5s\n",
      "ðŸ“Š  ValLoss=0.2857\n",
      "ðŸŒ€ Fold 1 | Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 1 | Epoch 9 done | TrainLoss=0.1713 | Time=260.8s\n",
      "ðŸ“Š  ValLoss=0.2702\n",
      "ðŸŒ€ Fold 1 | Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 1 | Epoch 10 done | TrainLoss=0.1492 | Time=261.0s\n",
      "ðŸ“Š  ValLoss=0.2610\n",
      "ðŸŒ€ Fold 1 | Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 1 | Epoch 11 done | TrainLoss=0.1312 | Time=261.6s\n",
      "ðŸ“Š  ValLoss=0.2506\n",
      "ðŸŒ€ Fold 1 | Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 1 | Epoch 12 done | TrainLoss=0.1177 | Time=261.0s\n",
      "ðŸ“Š  ValLoss=0.2205\n",
      "ðŸŒ€ Fold 1 | Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 1 | Epoch 13 done | TrainLoss=0.0999 | Time=261.5s\n",
      "ðŸ“Š  ValLoss=0.2196\n",
      "ðŸŒ€ Fold 1 | Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 1 | Epoch 14 done | TrainLoss=0.0891 | Time=261.7s\n",
      "ðŸ“Š  ValLoss=0.2403\n",
      "ðŸŒ€ Fold 1 | Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 1 | Epoch 15 done | TrainLoss=0.0781 | Time=261.7s\n",
      "ðŸ“Š  ValLoss=0.2395\n",
      "ðŸŒ€ Fold 1 | Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 1 | Epoch 16 done | TrainLoss=0.0658 | Time=261.6s\n",
      "ðŸ“Š  ValLoss=0.2295\n",
      "ðŸŒ€ Fold 1 | Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 1 | Epoch 17 done | TrainLoss=0.0594 | Time=261.5s\n",
      "ðŸ“Š  ValLoss=0.2339\n",
      "ðŸŒ€ Fold 1 | Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 1 | Epoch 18 done | TrainLoss=0.0527 | Time=261.4s\n",
      "ðŸ“Š  ValLoss=0.2415\n",
      "ðŸŒ€ Fold 1 | Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 1 | Epoch 19 done | TrainLoss=0.0496 | Time=260.4s\n",
      "ðŸ“Š  ValLoss=0.2366\n",
      "ðŸŒ€ Fold 1 | Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 1 | Epoch 20 done | TrainLoss=0.0463 | Time=261.2s\n",
      "ðŸ“Š  ValLoss=0.2374\n",
      "\n",
      "â•â•â•â• FOLD 2/5 â•â•â•â•\n",
      "ðŸŒ€ Fold 2 | Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 2 | Epoch 1 done | TrainLoss=0.9181 | Time=261.2s\n",
      "ðŸ“Š  ValLoss=0.6789\n",
      "ðŸŒ€ Fold 2 | Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 2 | Epoch 2 done | TrainLoss=0.5301 | Time=261.5s\n",
      "ðŸ“Š  ValLoss=0.5187\n",
      "ðŸŒ€ Fold 2 | Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 2 | Epoch 3 done | TrainLoss=0.3969 | Time=259.9s\n",
      "ðŸ“Š  ValLoss=0.3665\n",
      "ðŸŒ€ Fold 2 | Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 2 | Epoch 4 done | TrainLoss=0.3285 | Time=260.9s\n",
      "ðŸ“Š  ValLoss=0.3188\n",
      "ðŸŒ€ Fold 2 | Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 2 | Epoch 5 done | TrainLoss=0.2902 | Time=260.9s\n",
      "ðŸ“Š  ValLoss=0.3285\n",
      "ðŸŒ€ Fold 2 | Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 2 | Epoch 6 done | TrainLoss=0.2522 | Time=260.6s\n",
      "ðŸ“Š  ValLoss=0.2975\n",
      "ðŸŒ€ Fold 2 | Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 2 | Epoch 7 done | TrainLoss=0.2232 | Time=261.1s\n",
      "ðŸ“Š  ValLoss=0.3084\n",
      "ðŸŒ€ Fold 2 | Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 2 | Epoch 8 done | TrainLoss=0.1979 | Time=260.9s\n",
      "ðŸ“Š  ValLoss=0.3087\n",
      "ðŸŒ€ Fold 2 | Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 2 | Epoch 9 done | TrainLoss=0.1740 | Time=261.0s\n",
      "ðŸ“Š  ValLoss=0.3282\n",
      "ðŸŒ€ Fold 2 | Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 2 | Epoch 10 done | TrainLoss=0.1563 | Time=260.0s\n",
      "ðŸ“Š  ValLoss=0.2362\n",
      "ðŸŒ€ Fold 2 | Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 2 | Epoch 11 done | TrainLoss=0.1401 | Time=260.6s\n",
      "ðŸ“Š  ValLoss=0.2292\n",
      "ðŸŒ€ Fold 2 | Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 2 | Epoch 12 done | TrainLoss=0.1198 | Time=261.0s\n",
      "ðŸ“Š  ValLoss=0.2540\n",
      "ðŸŒ€ Fold 2 | Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 2 | Epoch 13 done | TrainLoss=0.1019 | Time=261.1s\n",
      "ðŸ“Š  ValLoss=0.2236\n",
      "ðŸŒ€ Fold 2 | Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 2 | Epoch 14 done | TrainLoss=0.0898 | Time=261.0s\n",
      "ðŸ“Š  ValLoss=0.2144\n",
      "ðŸŒ€ Fold 2 | Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 2 | Epoch 15 done | TrainLoss=0.0778 | Time=260.9s\n",
      "ðŸ“Š  ValLoss=0.2177\n",
      "ðŸŒ€ Fold 2 | Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 2 | Epoch 16 done | TrainLoss=0.0681 | Time=261.2s\n",
      "ðŸ“Š  ValLoss=0.2312\n",
      "ðŸŒ€ Fold 2 | Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 2 | Epoch 17 done | TrainLoss=0.0604 | Time=261.0s\n",
      "ðŸ“Š  ValLoss=0.2171\n",
      "ðŸŒ€ Fold 2 | Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 2 | Epoch 18 done | TrainLoss=0.0540 | Time=261.1s\n",
      "ðŸ“Š  ValLoss=0.2247\n",
      "ðŸŒ€ Fold 2 | Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 2 | Epoch 19 done | TrainLoss=0.0501 | Time=261.4s\n",
      "ðŸ“Š  ValLoss=0.2234\n",
      "ðŸŒ€ Fold 2 | Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 2 | Epoch 20 done | TrainLoss=0.0475 | Time=261.3s\n",
      "ðŸ“Š  ValLoss=0.2231\n",
      "\n",
      "â•â•â•â• FOLD 3/5 â•â•â•â•\n",
      "ðŸŒ€ Fold 3 | Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 3 | Epoch 1 done | TrainLoss=0.8889 | Time=261.3s\n",
      "ðŸ“Š  ValLoss=0.6173\n",
      "ðŸŒ€ Fold 3 | Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 3 | Epoch 2 done | TrainLoss=0.5205 | Time=261.1s\n",
      "ðŸ“Š  ValLoss=0.4370\n",
      "ðŸŒ€ Fold 3 | Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 3 | Epoch 3 done | TrainLoss=0.3983 | Time=261.2s\n",
      "ðŸ“Š  ValLoss=0.3986\n",
      "ðŸŒ€ Fold 3 | Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 3 | Epoch 4 done | TrainLoss=0.3367 | Time=261.6s\n",
      "ðŸ“Š  ValLoss=0.3832\n",
      "ðŸŒ€ Fold 3 | Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 3 | Epoch 5 done | TrainLoss=0.2876 | Time=261.0s\n",
      "ðŸ“Š  ValLoss=0.3383\n",
      "ðŸŒ€ Fold 3 | Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 3 | Epoch 6 done | TrainLoss=0.2516 | Time=260.8s\n",
      "ðŸ“Š  ValLoss=0.2832\n",
      "ðŸŒ€ Fold 3 | Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 3 | Epoch 7 done | TrainLoss=0.2246 | Time=261.0s\n",
      "ðŸ“Š  ValLoss=0.2453\n",
      "ðŸŒ€ Fold 3 | Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 3 | Epoch 8 done | TrainLoss=0.1979 | Time=260.9s\n",
      "ðŸ“Š  ValLoss=0.2348\n",
      "ðŸŒ€ Fold 3 | Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 3 | Epoch 9 done | TrainLoss=0.1718 | Time=259.7s\n",
      "ðŸ“Š  ValLoss=0.2532\n",
      "ðŸŒ€ Fold 3 | Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 3 | Epoch 10 done | TrainLoss=0.1526 | Time=260.7s\n",
      "ðŸ“Š  ValLoss=0.1986\n",
      "ðŸŒ€ Fold 3 | Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 3 | Epoch 11 done | TrainLoss=0.1337 | Time=260.9s\n",
      "ðŸ“Š  ValLoss=0.2080\n",
      "ðŸŒ€ Fold 3 | Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 3 | Epoch 12 done | TrainLoss=0.1165 | Time=259.8s\n",
      "ðŸ“Š  ValLoss=0.1962\n",
      "ðŸŒ€ Fold 3 | Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 3 | Epoch 13 done | TrainLoss=0.1020 | Time=260.2s\n",
      "ðŸ“Š  ValLoss=0.1863\n",
      "ðŸŒ€ Fold 3 | Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 3 | Epoch 14 done | TrainLoss=0.0900 | Time=258.1s\n",
      "ðŸ“Š  ValLoss=0.1885\n",
      "ðŸŒ€ Fold 3 | Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 3 | Epoch 15 done | TrainLoss=0.0765 | Time=259.8s\n",
      "ðŸ“Š  ValLoss=0.1936\n",
      "ðŸŒ€ Fold 3 | Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 3 | Epoch 16 done | TrainLoss=0.0672 | Time=261.0s\n",
      "ðŸ“Š  ValLoss=0.2014\n",
      "ðŸŒ€ Fold 3 | Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 3 | Epoch 17 done | TrainLoss=0.0586 | Time=260.1s\n",
      "ðŸ“Š  ValLoss=0.1948\n",
      "ðŸŒ€ Fold 3 | Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 3 | Epoch 18 done | TrainLoss=0.0525 | Time=261.4s\n",
      "ðŸ“Š  ValLoss=0.2021\n",
      "ðŸŒ€ Fold 3 | Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 3 | Epoch 19 done | TrainLoss=0.0483 | Time=261.0s\n",
      "ðŸ“Š  ValLoss=0.1963\n",
      "ðŸŒ€ Fold 3 | Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 3 | Epoch 20 done | TrainLoss=0.0463 | Time=261.0s\n",
      "ðŸ“Š  ValLoss=0.1946\n",
      "\n",
      "â•â•â•â• FOLD 4/5 â•â•â•â•\n",
      "ðŸŒ€ Fold 4 | Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 4 | Epoch 1 done | TrainLoss=0.8846 | Time=261.3s\n",
      "ðŸ“Š  ValLoss=0.5519\n",
      "ðŸŒ€ Fold 4 | Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 4 | Epoch 2 done | TrainLoss=0.5331 | Time=261.0s\n",
      "ðŸ“Š  ValLoss=0.5639\n",
      "ðŸŒ€ Fold 4 | Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 4 | Epoch 3 done | TrainLoss=0.3972 | Time=260.6s\n",
      "ðŸ“Š  ValLoss=0.4148\n",
      "ðŸŒ€ Fold 4 | Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 4 | Epoch 4 done | TrainLoss=0.3360 | Time=261.6s\n",
      "ðŸ“Š  ValLoss=0.3111\n",
      "ðŸŒ€ Fold 4 | Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 4 | Epoch 5 done | TrainLoss=0.2885 | Time=261.3s\n",
      "ðŸ“Š  ValLoss=0.3057\n",
      "ðŸŒ€ Fold 4 | Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 4 | Epoch 6 done | TrainLoss=0.2629 | Time=261.1s\n",
      "ðŸ“Š  ValLoss=0.2766\n",
      "ðŸŒ€ Fold 4 | Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 4 | Epoch 7 done | TrainLoss=0.2276 | Time=260.6s\n",
      "ðŸ“Š  ValLoss=0.2749\n",
      "ðŸŒ€ Fold 4 | Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 4 | Epoch 8 done | TrainLoss=0.1965 | Time=258.8s\n",
      "ðŸ“Š  ValLoss=0.3321\n",
      "ðŸŒ€ Fold 4 | Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 4 | Epoch 9 done | TrainLoss=0.1816 | Time=260.4s\n",
      "ðŸ“Š  ValLoss=0.2654\n",
      "ðŸŒ€ Fold 4 | Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 4 | Epoch 10 done | TrainLoss=0.1561 | Time=260.9s\n",
      "ðŸ“Š  ValLoss=0.2342\n",
      "ðŸŒ€ Fold 4 | Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 4 | Epoch 11 done | TrainLoss=0.1340 | Time=260.7s\n",
      "ðŸ“Š  ValLoss=0.2431\n",
      "ðŸŒ€ Fold 4 | Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 4 | Epoch 12 done | TrainLoss=0.1188 | Time=260.9s\n",
      "ðŸ“Š  ValLoss=0.2015\n",
      "ðŸŒ€ Fold 4 | Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 4 | Epoch 13 done | TrainLoss=0.1007 | Time=260.3s\n",
      "ðŸ“Š  ValLoss=0.2067\n",
      "ðŸŒ€ Fold 4 | Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 4 | Epoch 14 done | TrainLoss=0.0891 | Time=260.3s\n",
      "ðŸ“Š  ValLoss=0.2109\n",
      "ðŸŒ€ Fold 4 | Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 4 | Epoch 15 done | TrainLoss=0.0780 | Time=260.7s\n",
      "ðŸ“Š  ValLoss=0.1873\n",
      "ðŸŒ€ Fold 4 | Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 4 | Epoch 16 done | TrainLoss=0.0677 | Time=260.9s\n",
      "ðŸ“Š  ValLoss=0.1920\n",
      "ðŸŒ€ Fold 4 | Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 4 | Epoch 17 done | TrainLoss=0.0591 | Time=260.6s\n",
      "ðŸ“Š  ValLoss=0.2011\n",
      "ðŸŒ€ Fold 4 | Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 4 | Epoch 18 done | TrainLoss=0.0546 | Time=261.4s\n",
      "ðŸ“Š  ValLoss=0.2006\n",
      "ðŸŒ€ Fold 4 | Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 4 | Epoch 19 done | TrainLoss=0.0496 | Time=260.9s\n",
      "ðŸ“Š  ValLoss=0.1996\n",
      "ðŸŒ€ Fold 4 | Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 4 | Epoch 20 done | TrainLoss=0.0474 | Time=261.4s\n",
      "ðŸ“Š  ValLoss=0.1969\n",
      "\n",
      "â•â•â•â• FOLD 5/5 â•â•â•â•\n",
      "ðŸŒ€ Fold 5 | Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 5 | Epoch 1 done | TrainLoss=0.8815 | Time=260.9s\n",
      "ðŸ“Š  ValLoss=0.6597\n",
      "ðŸŒ€ Fold 5 | Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 5 | Epoch 2 done | TrainLoss=0.5205 | Time=261.1s\n",
      "ðŸ“Š  ValLoss=0.4242\n",
      "ðŸŒ€ Fold 5 | Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 5 | Epoch 3 done | TrainLoss=0.4003 | Time=260.6s\n",
      "ðŸ“Š  ValLoss=0.4276\n",
      "ðŸŒ€ Fold 5 | Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 5 | Epoch 4 done | TrainLoss=0.3404 | Time=260.5s\n",
      "ðŸ“Š  ValLoss=0.3641\n",
      "ðŸŒ€ Fold 5 | Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 5 | Epoch 5 done | TrainLoss=0.2905 | Time=260.4s\n",
      "ðŸ“Š  ValLoss=0.3418\n",
      "ðŸŒ€ Fold 5 | Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 5 | Epoch 6 done | TrainLoss=0.2570 | Time=260.7s\n",
      "ðŸ“Š  ValLoss=0.2628\n",
      "ðŸŒ€ Fold 5 | Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 5 | Epoch 7 done | TrainLoss=0.2252 | Time=260.4s\n",
      "ðŸ“Š  ValLoss=0.2931\n",
      "ðŸŒ€ Fold 5 | Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 5 | Epoch 8 done | TrainLoss=0.2016 | Time=259.8s\n",
      "ðŸ“Š  ValLoss=0.2767\n",
      "ðŸŒ€ Fold 5 | Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 5 | Epoch 9 done | TrainLoss=0.1758 | Time=260.4s\n",
      "ðŸ“Š  ValLoss=0.2296\n",
      "ðŸŒ€ Fold 5 | Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 5 | Epoch 10 done | TrainLoss=0.1534 | Time=260.9s\n",
      "ðŸ“Š  ValLoss=0.2341\n",
      "ðŸŒ€ Fold 5 | Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 5 | Epoch 11 done | TrainLoss=0.1362 | Time=260.0s\n",
      "ðŸ“Š  ValLoss=0.2365\n",
      "ðŸŒ€ Fold 5 | Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 5 | Epoch 12 done | TrainLoss=0.1160 | Time=260.5s\n",
      "ðŸ“Š  ValLoss=0.2477\n",
      "ðŸŒ€ Fold 5 | Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 5 | Epoch 13 done | TrainLoss=0.1018 | Time=260.6s\n",
      "ðŸ“Š  ValLoss=0.2228\n",
      "ðŸŒ€ Fold 5 | Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 5 | Epoch 14 done | TrainLoss=0.0866 | Time=260.6s\n",
      "ðŸ“Š  ValLoss=0.2109\n",
      "ðŸŒ€ Fold 5 | Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 5 | Epoch 15 done | TrainLoss=0.0736 | Time=260.4s\n",
      "ðŸ“Š  ValLoss=0.2278\n",
      "ðŸŒ€ Fold 5 | Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 5 | Epoch 16 done | TrainLoss=0.0642 | Time=260.3s\n",
      "ðŸ“Š  ValLoss=0.2300\n",
      "ðŸŒ€ Fold 5 | Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 5 | Epoch 17 done | TrainLoss=0.0586 | Time=260.7s\n",
      "ðŸ“Š  ValLoss=0.2132\n",
      "ðŸŒ€ Fold 5 | Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 5 | Epoch 18 done | TrainLoss=0.0511 | Time=261.0s\n",
      "ðŸ“Š  ValLoss=0.2215\n",
      "ðŸŒ€ Fold 5 | Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 5 | Epoch 19 done | TrainLoss=0.0481 | Time=260.3s\n",
      "ðŸ“Š  ValLoss=0.2187\n",
      "ðŸŒ€ Fold 5 | Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold 5 | Epoch 20 done | TrainLoss=0.0461 | Time=260.7s\n",
      "ðŸ“Š  ValLoss=0.2196\n"
     ]
    }
   ],
   "source": [
    "# encoder_only_kfold_debug.py â€“ versi siapÂ inference (updated)\n",
    "# Menyimpan best_model.pt, model_config.json, vocab.txt, confusion_fold.png,\n",
    "# final_summary_perkelas.csv, dan final_summary_best_only.csv (1 fold terbaik saja)\n",
    "\n",
    "import os, glob, gc, copy, math, random, time, json\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• KONFIGURASI â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "DATA_DIR    = \"/workspace/SPLIT_BEATS_NPY/train\"\n",
    "LABEL_MAP   = {'N':0,'L':1,'R':2,'V':3,'Q':4}\n",
    "SEED        = 42\n",
    "N_SPLITS    = 5\n",
    "EPOCHS      = 20\n",
    "BATCH_SIZE  = 32\n",
    "MAX_LEN     = 512\n",
    "EMB_DIM     = 512\n",
    "N_HEADS     = 8\n",
    "FF_DIM      = 2048\n",
    "N_LAYERS    = 12\n",
    "LR          = 2e-5\n",
    "OUTPUT_BASE = \"/workspace/HASIL_ENCODER/HASIL_4\"\n",
    "os.makedirs(OUTPUT_BASE, exist_ok=True)\n",
    "\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "PAD_ID, CLS_ID  = 256, 257\n",
    "VOCAB_SIZE      = 258\n",
    "cls_names       = list(LABEL_MAP.keys())\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â• UTILITAS â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def signal_to_ids(sig: np.ndarray):\n",
    "    norm = ((sig - sig.min()) / (sig.ptp() + 1e-8) * 255).astype(int)\n",
    "    ids  = np.concatenate(([CLS_ID], norm))[:MAX_LEN]\n",
    "    mask = np.ones_like(ids, dtype=int)\n",
    "    if len(ids) < MAX_LEN:\n",
    "        pad_len = MAX_LEN - len(ids)\n",
    "        ids  = np.concatenate((ids,  np.full(pad_len, PAD_ID,  dtype=int)))\n",
    "        mask = np.concatenate((mask, np.zeros(pad_len,       dtype=int)))\n",
    "    return ids, mask\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â• MUAT DATA â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "files, labels = [], []\n",
    "for cls, idx in LABEL_MAP.items():\n",
    "    for f in glob.glob(os.path.join(DATA_DIR, cls, \"*.npy\")):\n",
    "        files.append(f); labels.append(idx)\n",
    "files, labels = np.array(files), np.array(labels)\n",
    "\n",
    "print(\"Preâ€‘encoding semua sampel â€¦\")\n",
    "all_ids, all_mask = [], []\n",
    "for f in tqdm(files, total=len(files)):\n",
    "    ids, msk = signal_to_ids(np.load(f))\n",
    "    all_ids.append(ids);  all_mask.append(msk)\n",
    "all_ids  = torch.tensor(all_ids,  dtype=torch.long)\n",
    "all_mask = torch.tensor(all_mask, dtype=torch.long)\n",
    "labels_t = torch.tensor(labels,   dtype=torch.long)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â• DEFINISI MODEL â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "class EncoderOnlyClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(VOCAB_SIZE, EMB_DIM, padding_idx=PAD_ID)\n",
    "        self.pos_emb   = nn.Parameter(torch.zeros(1, MAX_LEN, EMB_DIM))\n",
    "        enc_layer = nn.TransformerEncoderLayer(d_model=EMB_DIM, nhead=N_HEADS, dim_feedforward=FF_DIM, dropout=0.1, batch_first=True)\n",
    "        self.encoder  = nn.TransformerEncoder(enc_layer, num_layers=N_LAYERS)\n",
    "        self.fc       = nn.Linear(EMB_DIM, len(LABEL_MAP))\n",
    "        nn.init.normal_(self.pos_emb, std=0.02)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        x = self.token_emb(input_ids) + self.pos_emb\n",
    "        x = self.encoder(x, src_key_padding_mask=~attention_mask.bool())\n",
    "        x = (x * attention_mask.unsqueeze(-1)).sum(1) / attention_mask.sum(1, keepdim=True).clamp(min=1e-9)\n",
    "        return self.fc(x)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â• Kâ€‘FOLD TRAINING â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "rows_all = []\n",
    "fold_val_losses = []\n",
    "\n",
    "for fold, (tr, va) in enumerate(skf.split(all_ids, labels), 1):\n",
    "    print(f\"\\nâ•â•â•â• FOLD {fold}/{N_SPLITS} â•â•â•â•\")\n",
    "    gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "    train_ds = TensorDataset(all_ids[tr], all_mask[tr], labels_t[tr])\n",
    "    val_ds   = TensorDataset(all_ids[va], all_mask[va], labels_t[va])\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE)\n",
    "\n",
    "    model = EncoderOnlyClassifier().to(DEVICE)\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, EPOCHS)\n",
    "\n",
    "    best_state, best_loss = None, math.inf\n",
    "    out_dir = os.path.join(OUTPUT_BASE, f\"fold{fold}\"); os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        start_t = time.time(); model.train(); tot_loss = 0\n",
    "        print(f\"\\U0001f300 Fold {fold} | Epoch {epoch}/{EPOCHS}\")\n",
    "        for ids, msk, lbl in tqdm(train_loader, leave=False):\n",
    "            ids, msk, lbl = ids.to(DEVICE), msk.to(DEVICE), lbl.to(DEVICE)\n",
    "            optim.zero_grad(); loss = F.cross_entropy(model(ids, msk), lbl)\n",
    "            loss.backward(); torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0); optim.step()\n",
    "            tot_loss += loss.item()\n",
    "        scheduler.step()\n",
    "        print(f\"âœ… Fold {fold} | Epoch {epoch} done | TrainLoss={tot_loss/len(train_loader):.4f} | Time={time.time()-start_t:.1f}s\")\n",
    "\n",
    "        model.eval(); val_loss, preds, yh = 0, [], []\n",
    "        with torch.no_grad():\n",
    "            for ids, msk, lbl in val_loader:\n",
    "                ids, msk, lbl = ids.to(DEVICE), msk.to(DEVICE), lbl.to(DEVICE)\n",
    "                out = model(ids, msk)\n",
    "                val_loss += F.cross_entropy(out, lbl, reduction='sum').item()\n",
    "                preds.append(out.argmax(1).cpu()); yh.append(lbl.cpu())\n",
    "        val_loss /= len(val_ds)\n",
    "        preds = torch.cat(preds).numpy(); y_true = torch.cat(yh).numpy()\n",
    "        print(f\"ðŸ“Š  ValLoss={val_loss:.4f}\")\n",
    "        if val_loss < best_loss:\n",
    "            best_loss, best_state = val_loss, copy.deepcopy(model.state_dict())\n",
    "\n",
    "    torch.save(best_state, os.path.join(out_dir, \"best_model.pt\"))\n",
    "    with open(os.path.join(out_dir, \"model_config.json\"), \"w\") as f:\n",
    "        json.dump({\"emb_dim\":EMB_DIM,\"n_layers\":N_LAYERS,\"n_heads\":N_HEADS,\"ff_dim\":FF_DIM,\"max_len\":MAX_LEN,\"vocab_size\":VOCAB_SIZE,\"pad_id\":PAD_ID,\"cls_id\":CLS_ID,\"label_map\":LABEL_MAP}, f, indent=2)\n",
    "    with open(os.path.join(out_dir, \"vocab.txt\"), \"w\") as f:\n",
    "        f.writelines([f\"{i}\\n\" for i in range(256)] + [\"[PAD]\\n\",\"[CLS]\\n\"])\n",
    "\n",
    "    model.load_state_dict(best_state); model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = []; y_true = []\n",
    "        for ids, msk, lbl in val_loader:\n",
    "            ids, msk = ids.to(DEVICE), msk.to(DEVICE)\n",
    "            logits.append(model(ids, msk).cpu()); y_true.append(lbl)\n",
    "    preds = torch.cat(logits).argmax(1).numpy(); y_true = torch.cat(y_true).numpy()\n",
    "\n",
    "    cm = confusion_matrix(y_true, preds, labels=list(range(len(cls_names))))\n",
    "    plt.figure(figsize=(7,6)); plt.imshow(cm, cmap='Blues'); plt.title(f\"Confusion Fold {fold}\")\n",
    "    plt.xticks(range(len(cls_names)), cls_names); plt.yticks(range(len(cls_names)), cls_names)\n",
    "    for r in range(len(cm)):\n",
    "        for c in range(len(cm)):\n",
    "            plt.text(c, r, cm[r,c], ha='center', va='center')\n",
    "    plt.xlabel('Predicted'); plt.ylabel('True'); plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_dir, \"confusion_fold.png\")); plt.close()\n",
    "\n",
    "    fold_val_losses.append((fold, best_loss))\n",
    "    for i, cls in enumerate(cls_names):\n",
    "        TP = cm[i,i]; FN = cm[i].sum()-TP; FP = cm[:,i].sum()-TP; TN = cm.sum()-TP-FN-FP\n",
    "        ACC  = (TP+TN)/cm.sum(); REC = TP/(TP+FN+1e-8); SPEC = TN/(TN+FP+1e-8); F1 = 2*TP/(2*TP+FP+FN+1e-8)\n",
    "        rows_all.append({\"fold\": fold, \"kelas\": cls, \"akurasi\": round(ACC,4), \"f1\": round(F1,4), \"recall\": round(REC,4), \"spesifisitas\": round(SPEC,4)})\n",
    "\n",
    "# Simpan metrik ke CSV akhir\n",
    "out_df = pd.DataFrame(rows_all)\n",
    "out_df.to_csv(os.path.join(OUTPUT_BASE, \"final_summary_perkelas.csv\"), index=False)\n",
    "\n",
    "# Ambil hanya fold terbaik berdasarkan val_loss terendah\n",
    "best_fold = sorted(fold_val_losses, key=lambda x: x[1])[0][0]\n",
    "out_df[out_df.fold == best_fold].to_csv(os.path.join(OUTPUT_BASE, \"final_summary_best_only.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09bec5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 110/110 [06:56<00:00,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Evaluasi selesai. Hasil disimpan di: D:\\KULIAH\\TELKOM_UNIVERSITY\\SEMESTER_8\\TA\\TA_SKRIPSI_GUE\\HASIL_AKHIR_RECORD\\BEATS\\EVALUASI_DECODER_TEST\n"
     ]
    }
   ],
   "source": [
    "import os, json, torch, numpy as np, matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIG ===\n",
    "MODEL_PATH   = r\"D:\\KULIAH\\TELKOM_UNIVERSITY\\SEMESTER_8\\TA\\TA_SKRIPSI_GUE\\HASIL_TRAIN\\BEATS\\HASIL_DECODER\\HASIL_2\\fold4\\best_model.pt\"\n",
    "CONFIG_PATH  = r\"D:\\KULIAH\\TELKOM_UNIVERSITY\\SEMESTER_8\\TA\\TA_SKRIPSI_GUE\\HASIL_TRAIN\\BEATS\\HASIL_DECODER\\HASIL_2\\fold4\\model_config.json\"\n",
    "TEST_DIR     = r\"D:\\KULIAH\\TELKOM_UNIVERSITY\\SEMESTER_8\\TA\\TA_SKRIPSI_GUE\\DATA\\output_coba\\SPLIT_BEATS_NPY\\Beats_TEST\"\n",
    "OUTPUT_DIR   = r\"D:\\KULIAH\\TELKOM_UNIVERSITY\\SEMESTER_8\\TA\\TA_SKRIPSI_GUE\\HASIL_AKHIR_RECORD\\BEATS\\EVALUASI_DECODER_TEST\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# === Load config ===\n",
    "with open(CONFIG_PATH) as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "PAD_ID = config[\"pad_id\"]\n",
    "CLS_ID = config[\"cls_id\"]\n",
    "LABEL_MAP = config[\"label_map\"]\n",
    "IDX2LABEL = {v: k for k, v in LABEL_MAP.items()}\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === Define Decoder-Only Model ===\n",
    "class DecoderOnlyClassifier(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(config[\"vocab_size\"], config[\"emb_dim\"], padding_idx=PAD_ID)\n",
    "        self.pos_emb = nn.Parameter(torch.randn(1, config[\"max_len\"], config[\"emb_dim\"]))\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=config[\"emb_dim\"],\n",
    "            nhead=config[\"n_heads\"],\n",
    "            dim_feedforward=config[\"ff_dim\"],\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=config[\"n_layers\"])\n",
    "        self.fc = nn.Linear(config[\"emb_dim\"], len(config[\"label_map\"]))\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        x = self.token_emb(input_ids) + self.pos_emb[:, :input_ids.size(1), :]\n",
    "        memory = x.clone()\n",
    "        x = self.decoder(tgt=x, memory=memory, tgt_key_padding_mask=~attention_mask.bool())\n",
    "        x = (x * attention_mask.unsqueeze(-1)).sum(1) / attention_mask.sum(1, keepdim=True).clamp(min=1e-9)\n",
    "        return self.fc(x)\n",
    "\n",
    "# === Load Model ===\n",
    "model = DecoderOnlyClassifier(config).to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "# === Data Loader ===\n",
    "def signal_to_ids(sig):\n",
    "    norm = ((sig - sig.min()) / (sig.ptp() + 1e-8)) * 255\n",
    "    ids = [CLS_ID] + norm.astype(int).tolist()[:config[\"max_len\"] - 1]\n",
    "    mask = [1] * len(ids)\n",
    "    if len(ids) < config[\"max_len\"]:\n",
    "        pad_len = config[\"max_len\"] - len(ids)\n",
    "        ids += [PAD_ID] * pad_len\n",
    "        mask += [0] * pad_len\n",
    "    return torch.tensor(ids), torch.tensor(mask)\n",
    "\n",
    "X, M, Y = [], [], []\n",
    "for label in os.listdir(TEST_DIR):\n",
    "    label_path = os.path.join(TEST_DIR, label)\n",
    "    if not os.path.isdir(label_path): continue\n",
    "    for fname in os.listdir(label_path):\n",
    "        fpath = os.path.join(label_path, fname)\n",
    "        try:\n",
    "            sig = np.load(fpath)\n",
    "            ids, msk = signal_to_ids(sig)\n",
    "            X.append(ids); M.append(msk); Y.append(LABEL_MAP[label])\n",
    "        except:\n",
    "            print(f\"[WARNING] Failed to load {fpath}\")\n",
    "\n",
    "X = torch.stack(X)\n",
    "M = torch.stack(M)\n",
    "Y = torch.tensor(Y)\n",
    "\n",
    "# === Inference ===\n",
    "BATCH_SIZE = 64\n",
    "y_pred, y_true = [], []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, len(X), BATCH_SIZE)):\n",
    "        xb = X[i:i+BATCH_SIZE].to(DEVICE)\n",
    "        mb = M[i:i+BATCH_SIZE].to(DEVICE)\n",
    "        logits = model(xb, mb)\n",
    "        pred = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        y_pred.extend(pred)\n",
    "        y_true.extend(Y[i:i+BATCH_SIZE].numpy())\n",
    "\n",
    "# === Evaluation ===\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "rec = recall_score(y_true, y_pred, average='macro')\n",
    "f1  = f1_score(y_true, y_pred, average='macro')\n",
    "cm  = confusion_matrix(y_true, y_pred, labels=list(IDX2LABEL.keys()))\n",
    "\n",
    "# === Save Confusion Matrix ===\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.imshow(cm, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix - TEST SET\")\n",
    "plt.xticks(ticks=range(len(IDX2LABEL)), labels=IDX2LABEL.values())\n",
    "plt.yticks(ticks=range(len(IDX2LABEL)), labels=IDX2LABEL.values())\n",
    "for i in range(len(cm)):\n",
    "    for j in range(len(cm)):\n",
    "        plt.text(j, i, cm[i, j], ha='center', va='center')\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"confusion_test.png\"))\n",
    "plt.close()\n",
    "\n",
    "# === Save CSV Metrics Per Kelas ===\n",
    "rows = []\n",
    "for i, label in IDX2LABEL.items():\n",
    "    TP = cm[i,i]\n",
    "    FN = cm[i].sum() - TP\n",
    "    FP = cm[:,i].sum() - TP\n",
    "    TN = cm.sum() - TP - FN - FP\n",
    "    acc_cls  = (TP + TN) / cm.sum()\n",
    "    rec_cls  = TP / (TP + FN + 1e-8)\n",
    "    spec_cls = TN / (TN + FP + 1e-8)\n",
    "    f1_cls   = 2 * TP / (2 * TP + FP + FN + 1e-8)\n",
    "    rows.append({\n",
    "        \"kelas\": label,\n",
    "        \"akurasi\": round(acc_cls, 4),\n",
    "        \"recall\": round(rec_cls, 4),\n",
    "        \"f1\": round(f1_cls, 4),\n",
    "        \"spesifisitas\": round(spec_cls, 4)\n",
    "    })\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(os.path.join(OUTPUT_DIR, \"summary_test_metrics.csv\"), index=False)\n",
    "\n",
    "print(\"âœ… Evaluasi selesai. Hasil disimpan di:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "802173ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/110 [00:00<?, ?it/s]c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:505: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\NestedTensorImpl.cpp:182.)\n",
      "  output = torch._nested_tensor_from_mask(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 110/110 [06:13<00:00,  3.40s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Evaluasi ENCODER test selesai. Semua file disimpan di: D:\\KULIAH\\TELKOM_UNIVERSITY\\SEMESTER_8\\TA\\TA_SKRIPSI_GUE\\HASIL_AKHIR_RECORD\\BEATS\\EVALUASI_ENCODER_TEST\n"
     ]
    }
   ],
   "source": [
    "import os, json, torch, numpy as np, matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === KONFIGURASI ===\n",
    "MODEL_PATH   = r\"D:\\KULIAH\\TELKOM_UNIVERSITY\\SEMESTER_8\\TA\\TA_SKRIPSI_GUE\\HASIL_TRAIN\\BEATS\\HASIL_ENCODER\\HASIL_4\\fold4\\best_model.pt\"\n",
    "CONFIG_PATH  = r\"D:\\KULIAH\\TELKOM_UNIVERSITY\\SEMESTER_8\\TA\\TA_SKRIPSI_GUE\\HASIL_TRAIN\\BEATS\\HASIL_ENCODER\\HASIL_4\\fold4\\model_config.json\"\n",
    "TEST_DIR     = r\"D:\\KULIAH\\TELKOM_UNIVERSITY\\SEMESTER_8\\TA\\TA_SKRIPSI_GUE\\DATA\\output_coba\\SPLIT_BEATS_NPY\\Beats_TEST\"\n",
    "OUTPUT_DIR   = r\"D:\\KULIAH\\TELKOM_UNIVERSITY\\SEMESTER_8\\TA\\TA_SKRIPSI_GUE\\HASIL_AKHIR_RECORD\\BEATS\\EVALUASI_ENCODER_TEST\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# === Load config ===\n",
    "with open(CONFIG_PATH) as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "PAD_ID = config[\"pad_id\"]\n",
    "CLS_ID = config[\"cls_id\"]\n",
    "LABEL_MAP = config[\"label_map\"]\n",
    "IDX2LABEL = {v: k for k, v in LABEL_MAP.items()}\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === Definisi Model Encoder ===\n",
    "class EncoderOnlyClassifier(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(config[\"vocab_size\"], config[\"emb_dim\"], padding_idx=PAD_ID)\n",
    "        self.pos_emb   = nn.Parameter(torch.zeros(1, config[\"max_len\"], config[\"emb_dim\"]))\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=config[\"emb_dim\"],\n",
    "            nhead=config[\"n_heads\"],\n",
    "            dim_feedforward=config[\"ff_dim\"],\n",
    "            dropout=0.1,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=config[\"n_layers\"])\n",
    "        self.fc = nn.Linear(config[\"emb_dim\"], len(config[\"label_map\"]))\n",
    "        nn.init.normal_(self.pos_emb, std=0.02)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        x = self.token_emb(input_ids) + self.pos_emb\n",
    "        x = self.encoder(x, src_key_padding_mask=~attention_mask.bool())\n",
    "        x = (x * attention_mask.unsqueeze(-1)).sum(1) / attention_mask.sum(1, keepdim=True).clamp(min=1e-8)\n",
    "        return self.fc(x)\n",
    "\n",
    "# === Load Model ===\n",
    "model = EncoderOnlyClassifier(config).to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "# === Fungsi Preprocessing Sinyal ===\n",
    "def signal_to_ids(sig):\n",
    "    norm = ((sig - sig.min()) / (sig.ptp() + 1e-8)) * 255\n",
    "    ids = [CLS_ID] + norm.astype(int).tolist()[:config[\"max_len\"] - 1]\n",
    "    mask = [1] * len(ids)\n",
    "    if len(ids) < config[\"max_len\"]:\n",
    "        pad_len = config[\"max_len\"] - len(ids)\n",
    "        ids += [PAD_ID] * pad_len\n",
    "        mask += [0] * pad_len\n",
    "    return torch.tensor(ids), torch.tensor(mask)\n",
    "\n",
    "# === Load Data Test ===\n",
    "X, M, Y = [], [], []\n",
    "for label in os.listdir(TEST_DIR):\n",
    "    label_path = os.path.join(TEST_DIR, label)\n",
    "    if not os.path.isdir(label_path): continue\n",
    "    for fname in os.listdir(label_path):\n",
    "        fpath = os.path.join(label_path, fname)\n",
    "        try:\n",
    "            sig = np.load(fpath)\n",
    "            ids, msk = signal_to_ids(sig)\n",
    "            X.append(ids); M.append(msk); Y.append(LABEL_MAP[label])\n",
    "        except:\n",
    "            print(f\"[WARNING] Failed to load {fpath}\")\n",
    "\n",
    "X = torch.stack(X)\n",
    "M = torch.stack(M)\n",
    "Y = torch.tensor(Y)\n",
    "\n",
    "# === Inference ===\n",
    "BATCH_SIZE = 64\n",
    "y_pred, y_true = [], []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, len(X), BATCH_SIZE)):\n",
    "        xb = X[i:i+BATCH_SIZE].to(DEVICE)\n",
    "        mb = M[i:i+BATCH_SIZE].to(DEVICE)\n",
    "        logits = model(xb, mb)\n",
    "        pred = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        y_pred.extend(pred)\n",
    "        y_true.extend(Y[i:i+BATCH_SIZE].numpy())\n",
    "\n",
    "# === Evaluasi Keseluruhan ===\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "rec = recall_score(y_true, y_pred, average='macro')\n",
    "f1  = f1_score(y_true, y_pred, average='macro')\n",
    "cm  = confusion_matrix(y_true, y_pred, labels=list(IDX2LABEL.keys()))\n",
    "\n",
    "# === Simpan Confusion Matrix PNG ===\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.imshow(cm, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix - TEST SET (Encoder)\")\n",
    "plt.xticks(ticks=range(len(IDX2LABEL)), labels=IDX2LABEL.values())\n",
    "plt.yticks(ticks=range(len(IDX2LABEL)), labels=IDX2LABEL.values())\n",
    "for i in range(len(cm)):\n",
    "    for j in range(len(cm)):\n",
    "        plt.text(j, i, cm[i, j], ha='center', va='center')\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"confusion_test_encoder.png\"))\n",
    "plt.close()\n",
    "\n",
    "# === Simpan CSV Metrik Per Kelas ===\n",
    "rows = []\n",
    "for i, label in IDX2LABEL.items():\n",
    "    TP = cm[i,i]\n",
    "    FN = cm[i].sum() - TP\n",
    "    FP = cm[:,i].sum() - TP\n",
    "    TN = cm.sum() - TP - FN - FP\n",
    "    acc_cls  = (TP + TN) / cm.sum()\n",
    "    rec_cls  = TP / (TP + FN + 1e-8)\n",
    "    spec_cls = TN / (TN + FP + 1e-8)\n",
    "    f1_cls   = 2 * TP / (2 * TP + FP + FN + 1e-8)\n",
    "    rows.append({\n",
    "        \"kelas\": label,\n",
    "        \"akurasi\": round(acc_cls, 4),\n",
    "        \"recall\": round(rec_cls, 4),\n",
    "        \"f1\": round(f1_cls, 4),\n",
    "        \"spesifisitas\": round(spec_cls, 4)\n",
    "    })\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(os.path.join(OUTPUT_DIR, \"summary_test_metrics_encoder.csv\"), index=False)\n",
    "\n",
    "print(\"âœ… Evaluasi ENCODER test selesai. Semua file disimpan di:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f23fa0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Contoh matrix dari gambar Anda\n",
    "cm = np.array([\n",
    "    [1254,  39,  25,  68, 14],\n",
    "    [  18, 1336,  0,  40,  6],\n",
    "    [  27,   8, 1348, 16,  1],\n",
    "    [  22,  45,  3, 1319, 11],\n",
    "    [  27,   9, 17,  16, 1331]\n",
    "])\n",
    "labels = ['N', 'L', 'R', 'V', 'Q']\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "ax = sns.heatmap(cm, annot=False, fmt='d', cmap='Blues',\n",
    "                 xticklabels=labels, yticklabels=labels, cbar=False)\n",
    "\n",
    "# Tambahkan angka secara manual agar bisa atur warnanya\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        value = cm[i, j]\n",
    "        color = \"white\" if i == j else \"black\"\n",
    "        ax.text(j + 0.5, i + 0.5, f\"{value}\",\n",
    "                ha='center', va='center',\n",
    "                color=color, fontsize=10)\n",
    "\n",
    "plt.title(\"Confusion Matrix - TEST SET (Encoder)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confmat_encoder_colored.png\", dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
