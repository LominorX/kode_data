{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7d85cff-6d28-47af-a3a1-dcbe929561a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
      "Requirement already satisfied: transformers==4.48.2 in /usr/local/lib/python3.10/dist-packages (4.48.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.7.0)\n",
      "Requirement already satisfied: accelerate==0.26.0 in /usr/local/lib/python3.10/dist-packages (0.26.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.10.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.2) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.2) (0.33.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.2) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.2) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.2) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.2) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.2) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.2) (0.5.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.26.0) (5.9.6)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.2) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.2) (4.4.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.2) (1.1.4)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.48.2) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.48.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.48.2) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.48.2) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.26.4 torch transformers==4.48.2 scikit-learn accelerate==0.26.0 matplotlib tqdm pandas seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "720282af-88b9-4a99-a278-961bdba34ad6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre‑encoding semua sampel …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28000/28000 [00:03<00:00, 8194.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "════ FOLD 1/5 ════\n",
      "🌀 Fold 1 | Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 1 | Epoch 1 done | TrainLoss=0.8875 | Time=261.4s\n",
      "📊  ValLoss=0.6863\n",
      "🌀 Fold 1 | Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 1 | Epoch 2 done | TrainLoss=0.5396 | Time=261.6s\n",
      "📊  ValLoss=0.5823\n",
      "🌀 Fold 1 | Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 1 | Epoch 3 done | TrainLoss=0.4140 | Time=261.7s\n",
      "📊  ValLoss=0.3920\n",
      "🌀 Fold 1 | Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 1 | Epoch 4 done | TrainLoss=0.3407 | Time=261.3s\n",
      "📊  ValLoss=0.4125\n",
      "🌀 Fold 1 | Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 1 | Epoch 5 done | TrainLoss=0.2934 | Time=261.4s\n",
      "📊  ValLoss=0.3479\n",
      "🌀 Fold 1 | Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 1 | Epoch 6 done | TrainLoss=0.2582 | Time=261.4s\n",
      "📊  ValLoss=0.3550\n",
      "🌀 Fold 1 | Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 1 | Epoch 7 done | TrainLoss=0.2210 | Time=261.4s\n",
      "📊  ValLoss=0.3040\n",
      "🌀 Fold 1 | Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 1 | Epoch 8 done | TrainLoss=0.1981 | Time=260.5s\n",
      "📊  ValLoss=0.2857\n",
      "🌀 Fold 1 | Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 1 | Epoch 9 done | TrainLoss=0.1713 | Time=260.8s\n",
      "📊  ValLoss=0.2702\n",
      "🌀 Fold 1 | Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 1 | Epoch 10 done | TrainLoss=0.1492 | Time=261.0s\n",
      "📊  ValLoss=0.2610\n",
      "🌀 Fold 1 | Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 1 | Epoch 11 done | TrainLoss=0.1312 | Time=261.6s\n",
      "📊  ValLoss=0.2506\n",
      "🌀 Fold 1 | Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 1 | Epoch 12 done | TrainLoss=0.1177 | Time=261.0s\n",
      "📊  ValLoss=0.2205\n",
      "🌀 Fold 1 | Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 1 | Epoch 13 done | TrainLoss=0.0999 | Time=261.5s\n",
      "📊  ValLoss=0.2196\n",
      "🌀 Fold 1 | Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 1 | Epoch 14 done | TrainLoss=0.0891 | Time=261.7s\n",
      "📊  ValLoss=0.2403\n",
      "🌀 Fold 1 | Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 1 | Epoch 15 done | TrainLoss=0.0781 | Time=261.7s\n",
      "📊  ValLoss=0.2395\n",
      "🌀 Fold 1 | Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 1 | Epoch 16 done | TrainLoss=0.0658 | Time=261.6s\n",
      "📊  ValLoss=0.2295\n",
      "🌀 Fold 1 | Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 1 | Epoch 17 done | TrainLoss=0.0594 | Time=261.5s\n",
      "📊  ValLoss=0.2339\n",
      "🌀 Fold 1 | Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 1 | Epoch 18 done | TrainLoss=0.0527 | Time=261.4s\n",
      "📊  ValLoss=0.2415\n",
      "🌀 Fold 1 | Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 1 | Epoch 19 done | TrainLoss=0.0496 | Time=260.4s\n",
      "📊  ValLoss=0.2366\n",
      "🌀 Fold 1 | Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 1 | Epoch 20 done | TrainLoss=0.0463 | Time=261.2s\n",
      "📊  ValLoss=0.2374\n",
      "\n",
      "════ FOLD 2/5 ════\n",
      "🌀 Fold 2 | Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 2 | Epoch 1 done | TrainLoss=0.9181 | Time=261.2s\n",
      "📊  ValLoss=0.6789\n",
      "🌀 Fold 2 | Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 2 | Epoch 2 done | TrainLoss=0.5301 | Time=261.5s\n",
      "📊  ValLoss=0.5187\n",
      "🌀 Fold 2 | Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 2 | Epoch 3 done | TrainLoss=0.3969 | Time=259.9s\n",
      "📊  ValLoss=0.3665\n",
      "🌀 Fold 2 | Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 2 | Epoch 4 done | TrainLoss=0.3285 | Time=260.9s\n",
      "📊  ValLoss=0.3188\n",
      "🌀 Fold 2 | Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 2 | Epoch 5 done | TrainLoss=0.2902 | Time=260.9s\n",
      "📊  ValLoss=0.3285\n",
      "🌀 Fold 2 | Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 2 | Epoch 6 done | TrainLoss=0.2522 | Time=260.6s\n",
      "📊  ValLoss=0.2975\n",
      "🌀 Fold 2 | Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 2 | Epoch 7 done | TrainLoss=0.2232 | Time=261.1s\n",
      "📊  ValLoss=0.3084\n",
      "🌀 Fold 2 | Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 2 | Epoch 8 done | TrainLoss=0.1979 | Time=260.9s\n",
      "📊  ValLoss=0.3087\n",
      "🌀 Fold 2 | Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 2 | Epoch 9 done | TrainLoss=0.1740 | Time=261.0s\n",
      "📊  ValLoss=0.3282\n",
      "🌀 Fold 2 | Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 2 | Epoch 10 done | TrainLoss=0.1563 | Time=260.0s\n",
      "📊  ValLoss=0.2362\n",
      "🌀 Fold 2 | Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 2 | Epoch 11 done | TrainLoss=0.1401 | Time=260.6s\n",
      "📊  ValLoss=0.2292\n",
      "🌀 Fold 2 | Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 2 | Epoch 12 done | TrainLoss=0.1198 | Time=261.0s\n",
      "📊  ValLoss=0.2540\n",
      "🌀 Fold 2 | Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 2 | Epoch 13 done | TrainLoss=0.1019 | Time=261.1s\n",
      "📊  ValLoss=0.2236\n",
      "🌀 Fold 2 | Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 2 | Epoch 14 done | TrainLoss=0.0898 | Time=261.0s\n",
      "📊  ValLoss=0.2144\n",
      "🌀 Fold 2 | Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 2 | Epoch 15 done | TrainLoss=0.0778 | Time=260.9s\n",
      "📊  ValLoss=0.2177\n",
      "🌀 Fold 2 | Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 2 | Epoch 16 done | TrainLoss=0.0681 | Time=261.2s\n",
      "📊  ValLoss=0.2312\n",
      "🌀 Fold 2 | Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 2 | Epoch 17 done | TrainLoss=0.0604 | Time=261.0s\n",
      "📊  ValLoss=0.2171\n",
      "🌀 Fold 2 | Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 2 | Epoch 18 done | TrainLoss=0.0540 | Time=261.1s\n",
      "📊  ValLoss=0.2247\n",
      "🌀 Fold 2 | Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 2 | Epoch 19 done | TrainLoss=0.0501 | Time=261.4s\n",
      "📊  ValLoss=0.2234\n",
      "🌀 Fold 2 | Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 2 | Epoch 20 done | TrainLoss=0.0475 | Time=261.3s\n",
      "📊  ValLoss=0.2231\n",
      "\n",
      "════ FOLD 3/5 ════\n",
      "🌀 Fold 3 | Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 3 | Epoch 1 done | TrainLoss=0.8889 | Time=261.3s\n",
      "📊  ValLoss=0.6173\n",
      "🌀 Fold 3 | Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 3 | Epoch 2 done | TrainLoss=0.5205 | Time=261.1s\n",
      "📊  ValLoss=0.4370\n",
      "🌀 Fold 3 | Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 3 | Epoch 3 done | TrainLoss=0.3983 | Time=261.2s\n",
      "📊  ValLoss=0.3986\n",
      "🌀 Fold 3 | Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 3 | Epoch 4 done | TrainLoss=0.3367 | Time=261.6s\n",
      "📊  ValLoss=0.3832\n",
      "🌀 Fold 3 | Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 3 | Epoch 5 done | TrainLoss=0.2876 | Time=261.0s\n",
      "📊  ValLoss=0.3383\n",
      "🌀 Fold 3 | Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 3 | Epoch 6 done | TrainLoss=0.2516 | Time=260.8s\n",
      "📊  ValLoss=0.2832\n",
      "🌀 Fold 3 | Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 3 | Epoch 7 done | TrainLoss=0.2246 | Time=261.0s\n",
      "📊  ValLoss=0.2453\n",
      "🌀 Fold 3 | Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 3 | Epoch 8 done | TrainLoss=0.1979 | Time=260.9s\n",
      "📊  ValLoss=0.2348\n",
      "🌀 Fold 3 | Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 3 | Epoch 9 done | TrainLoss=0.1718 | Time=259.7s\n",
      "📊  ValLoss=0.2532\n",
      "🌀 Fold 3 | Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 3 | Epoch 10 done | TrainLoss=0.1526 | Time=260.7s\n",
      "📊  ValLoss=0.1986\n",
      "🌀 Fold 3 | Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 3 | Epoch 11 done | TrainLoss=0.1337 | Time=260.9s\n",
      "📊  ValLoss=0.2080\n",
      "🌀 Fold 3 | Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 3 | Epoch 12 done | TrainLoss=0.1165 | Time=259.8s\n",
      "📊  ValLoss=0.1962\n",
      "🌀 Fold 3 | Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 3 | Epoch 13 done | TrainLoss=0.1020 | Time=260.2s\n",
      "📊  ValLoss=0.1863\n",
      "🌀 Fold 3 | Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 3 | Epoch 14 done | TrainLoss=0.0900 | Time=258.1s\n",
      "📊  ValLoss=0.1885\n",
      "🌀 Fold 3 | Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 3 | Epoch 15 done | TrainLoss=0.0765 | Time=259.8s\n",
      "📊  ValLoss=0.1936\n",
      "🌀 Fold 3 | Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 3 | Epoch 16 done | TrainLoss=0.0672 | Time=261.0s\n",
      "📊  ValLoss=0.2014\n",
      "🌀 Fold 3 | Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 3 | Epoch 17 done | TrainLoss=0.0586 | Time=260.1s\n",
      "📊  ValLoss=0.1948\n",
      "🌀 Fold 3 | Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 3 | Epoch 18 done | TrainLoss=0.0525 | Time=261.4s\n",
      "📊  ValLoss=0.2021\n",
      "🌀 Fold 3 | Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 3 | Epoch 19 done | TrainLoss=0.0483 | Time=261.0s\n",
      "📊  ValLoss=0.1963\n",
      "🌀 Fold 3 | Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 3 | Epoch 20 done | TrainLoss=0.0463 | Time=261.0s\n",
      "📊  ValLoss=0.1946\n",
      "\n",
      "════ FOLD 4/5 ════\n",
      "🌀 Fold 4 | Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 4 | Epoch 1 done | TrainLoss=0.8846 | Time=261.3s\n",
      "📊  ValLoss=0.5519\n",
      "🌀 Fold 4 | Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 4 | Epoch 2 done | TrainLoss=0.5331 | Time=261.0s\n",
      "📊  ValLoss=0.5639\n",
      "🌀 Fold 4 | Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 4 | Epoch 3 done | TrainLoss=0.3972 | Time=260.6s\n",
      "📊  ValLoss=0.4148\n",
      "🌀 Fold 4 | Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 4 | Epoch 4 done | TrainLoss=0.3360 | Time=261.6s\n",
      "📊  ValLoss=0.3111\n",
      "🌀 Fold 4 | Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 4 | Epoch 5 done | TrainLoss=0.2885 | Time=261.3s\n",
      "📊  ValLoss=0.3057\n",
      "🌀 Fold 4 | Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 4 | Epoch 6 done | TrainLoss=0.2629 | Time=261.1s\n",
      "📊  ValLoss=0.2766\n",
      "🌀 Fold 4 | Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 4 | Epoch 7 done | TrainLoss=0.2276 | Time=260.6s\n",
      "📊  ValLoss=0.2749\n",
      "🌀 Fold 4 | Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 4 | Epoch 8 done | TrainLoss=0.1965 | Time=258.8s\n",
      "📊  ValLoss=0.3321\n",
      "🌀 Fold 4 | Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 4 | Epoch 9 done | TrainLoss=0.1816 | Time=260.4s\n",
      "📊  ValLoss=0.2654\n",
      "🌀 Fold 4 | Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 4 | Epoch 10 done | TrainLoss=0.1561 | Time=260.9s\n",
      "📊  ValLoss=0.2342\n",
      "🌀 Fold 4 | Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 4 | Epoch 11 done | TrainLoss=0.1340 | Time=260.7s\n",
      "📊  ValLoss=0.2431\n",
      "🌀 Fold 4 | Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 4 | Epoch 12 done | TrainLoss=0.1188 | Time=260.9s\n",
      "📊  ValLoss=0.2015\n",
      "🌀 Fold 4 | Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 4 | Epoch 13 done | TrainLoss=0.1007 | Time=260.3s\n",
      "📊  ValLoss=0.2067\n",
      "🌀 Fold 4 | Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 4 | Epoch 14 done | TrainLoss=0.0891 | Time=260.3s\n",
      "📊  ValLoss=0.2109\n",
      "🌀 Fold 4 | Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 4 | Epoch 15 done | TrainLoss=0.0780 | Time=260.7s\n",
      "📊  ValLoss=0.1873\n",
      "🌀 Fold 4 | Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 4 | Epoch 16 done | TrainLoss=0.0677 | Time=260.9s\n",
      "📊  ValLoss=0.1920\n",
      "🌀 Fold 4 | Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 4 | Epoch 17 done | TrainLoss=0.0591 | Time=260.6s\n",
      "📊  ValLoss=0.2011\n",
      "🌀 Fold 4 | Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 4 | Epoch 18 done | TrainLoss=0.0546 | Time=261.4s\n",
      "📊  ValLoss=0.2006\n",
      "🌀 Fold 4 | Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 4 | Epoch 19 done | TrainLoss=0.0496 | Time=260.9s\n",
      "📊  ValLoss=0.1996\n",
      "🌀 Fold 4 | Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 4 | Epoch 20 done | TrainLoss=0.0474 | Time=261.4s\n",
      "📊  ValLoss=0.1969\n",
      "\n",
      "════ FOLD 5/5 ════\n",
      "🌀 Fold 5 | Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 5 | Epoch 1 done | TrainLoss=0.8815 | Time=260.9s\n",
      "📊  ValLoss=0.6597\n",
      "🌀 Fold 5 | Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 5 | Epoch 2 done | TrainLoss=0.5205 | Time=261.1s\n",
      "📊  ValLoss=0.4242\n",
      "🌀 Fold 5 | Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 5 | Epoch 3 done | TrainLoss=0.4003 | Time=260.6s\n",
      "📊  ValLoss=0.4276\n",
      "🌀 Fold 5 | Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 5 | Epoch 4 done | TrainLoss=0.3404 | Time=260.5s\n",
      "📊  ValLoss=0.3641\n",
      "🌀 Fold 5 | Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 5 | Epoch 5 done | TrainLoss=0.2905 | Time=260.4s\n",
      "📊  ValLoss=0.3418\n",
      "🌀 Fold 5 | Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 5 | Epoch 6 done | TrainLoss=0.2570 | Time=260.7s\n",
      "📊  ValLoss=0.2628\n",
      "🌀 Fold 5 | Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 5 | Epoch 7 done | TrainLoss=0.2252 | Time=260.4s\n",
      "📊  ValLoss=0.2931\n",
      "🌀 Fold 5 | Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 5 | Epoch 8 done | TrainLoss=0.2016 | Time=259.8s\n",
      "📊  ValLoss=0.2767\n",
      "🌀 Fold 5 | Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 5 | Epoch 9 done | TrainLoss=0.1758 | Time=260.4s\n",
      "📊  ValLoss=0.2296\n",
      "🌀 Fold 5 | Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 5 | Epoch 10 done | TrainLoss=0.1534 | Time=260.9s\n",
      "📊  ValLoss=0.2341\n",
      "🌀 Fold 5 | Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 5 | Epoch 11 done | TrainLoss=0.1362 | Time=260.0s\n",
      "📊  ValLoss=0.2365\n",
      "🌀 Fold 5 | Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 5 | Epoch 12 done | TrainLoss=0.1160 | Time=260.5s\n",
      "📊  ValLoss=0.2477\n",
      "🌀 Fold 5 | Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 5 | Epoch 13 done | TrainLoss=0.1018 | Time=260.6s\n",
      "📊  ValLoss=0.2228\n",
      "🌀 Fold 5 | Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 5 | Epoch 14 done | TrainLoss=0.0866 | Time=260.6s\n",
      "📊  ValLoss=0.2109\n",
      "🌀 Fold 5 | Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 5 | Epoch 15 done | TrainLoss=0.0736 | Time=260.4s\n",
      "📊  ValLoss=0.2278\n",
      "🌀 Fold 5 | Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 5 | Epoch 16 done | TrainLoss=0.0642 | Time=260.3s\n",
      "📊  ValLoss=0.2300\n",
      "🌀 Fold 5 | Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 5 | Epoch 17 done | TrainLoss=0.0586 | Time=260.7s\n",
      "📊  ValLoss=0.2132\n",
      "🌀 Fold 5 | Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 5 | Epoch 18 done | TrainLoss=0.0511 | Time=261.0s\n",
      "📊  ValLoss=0.2215\n",
      "🌀 Fold 5 | Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 5 | Epoch 19 done | TrainLoss=0.0481 | Time=260.3s\n",
      "📊  ValLoss=0.2187\n",
      "🌀 Fold 5 | Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold 5 | Epoch 20 done | TrainLoss=0.0461 | Time=260.7s\n",
      "📊  ValLoss=0.2196\n"
     ]
    }
   ],
   "source": [
    "# encoder_only_kfold_debug.py – versi siap inference (updated)\n",
    "# Menyimpan best_model.pt, model_config.json, vocab.txt, confusion_fold.png,\n",
    "# final_summary_perkelas.csv, dan final_summary_best_only.csv (1 fold terbaik saja)\n",
    "\n",
    "import os, glob, gc, copy, math, random, time, json\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ════════════════ KONFIGURASI ════════════════════════════\n",
    "DATA_DIR    = \"/workspace/SPLIT_BEATS_NPY/train\"\n",
    "LABEL_MAP   = {'N':0,'L':1,'R':2,'V':3,'Q':4}\n",
    "SEED        = 42\n",
    "N_SPLITS    = 5\n",
    "EPOCHS      = 20\n",
    "BATCH_SIZE  = 32\n",
    "MAX_LEN     = 512\n",
    "EMB_DIM     = 512\n",
    "N_HEADS     = 8\n",
    "FF_DIM      = 2048\n",
    "N_LAYERS    = 12\n",
    "LR          = 2e-5\n",
    "OUTPUT_BASE = \"/workspace/HASIL_ENCODER/HASIL_4\"\n",
    "os.makedirs(OUTPUT_BASE, exist_ok=True)\n",
    "\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "PAD_ID, CLS_ID  = 256, 257\n",
    "VOCAB_SIZE      = 258\n",
    "cls_names       = list(LABEL_MAP.keys())\n",
    "\n",
    "# ══════════════ UTILITAS ════════════════════════════\n",
    "\n",
    "def signal_to_ids(sig: np.ndarray):\n",
    "    norm = ((sig - sig.min()) / (sig.ptp() + 1e-8) * 255).astype(int)\n",
    "    ids  = np.concatenate(([CLS_ID], norm))[:MAX_LEN]\n",
    "    mask = np.ones_like(ids, dtype=int)\n",
    "    if len(ids) < MAX_LEN:\n",
    "        pad_len = MAX_LEN - len(ids)\n",
    "        ids  = np.concatenate((ids,  np.full(pad_len, PAD_ID,  dtype=int)))\n",
    "        mask = np.concatenate((mask, np.zeros(pad_len,       dtype=int)))\n",
    "    return ids, mask\n",
    "\n",
    "# ══════════════ MUAT DATA ════════════════════════════\n",
    "files, labels = [], []\n",
    "for cls, idx in LABEL_MAP.items():\n",
    "    for f in glob.glob(os.path.join(DATA_DIR, cls, \"*.npy\")):\n",
    "        files.append(f); labels.append(idx)\n",
    "files, labels = np.array(files), np.array(labels)\n",
    "\n",
    "print(\"Pre‑encoding semua sampel …\")\n",
    "all_ids, all_mask = [], []\n",
    "for f in tqdm(files, total=len(files)):\n",
    "    ids, msk = signal_to_ids(np.load(f))\n",
    "    all_ids.append(ids);  all_mask.append(msk)\n",
    "all_ids  = torch.tensor(all_ids,  dtype=torch.long)\n",
    "all_mask = torch.tensor(all_mask, dtype=torch.long)\n",
    "labels_t = torch.tensor(labels,   dtype=torch.long)\n",
    "\n",
    "# ══════════════ DEFINISI MODEL ══════════════════════════\n",
    "class EncoderOnlyClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(VOCAB_SIZE, EMB_DIM, padding_idx=PAD_ID)\n",
    "        self.pos_emb   = nn.Parameter(torch.zeros(1, MAX_LEN, EMB_DIM))\n",
    "        enc_layer = nn.TransformerEncoderLayer(d_model=EMB_DIM, nhead=N_HEADS, dim_feedforward=FF_DIM, dropout=0.1, batch_first=True)\n",
    "        self.encoder  = nn.TransformerEncoder(enc_layer, num_layers=N_LAYERS)\n",
    "        self.fc       = nn.Linear(EMB_DIM, len(LABEL_MAP))\n",
    "        nn.init.normal_(self.pos_emb, std=0.02)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        x = self.token_emb(input_ids) + self.pos_emb\n",
    "        x = self.encoder(x, src_key_padding_mask=~attention_mask.bool())\n",
    "        x = (x * attention_mask.unsqueeze(-1)).sum(1) / attention_mask.sum(1, keepdim=True).clamp(min=1e-9)\n",
    "        return self.fc(x)\n",
    "\n",
    "# ══════════════ K‑FOLD TRAINING ══════════════════════════\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "rows_all = []\n",
    "fold_val_losses = []\n",
    "\n",
    "for fold, (tr, va) in enumerate(skf.split(all_ids, labels), 1):\n",
    "    print(f\"\\n════ FOLD {fold}/{N_SPLITS} ════\")\n",
    "    gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "    train_ds = TensorDataset(all_ids[tr], all_mask[tr], labels_t[tr])\n",
    "    val_ds   = TensorDataset(all_ids[va], all_mask[va], labels_t[va])\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE)\n",
    "\n",
    "    model = EncoderOnlyClassifier().to(DEVICE)\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, EPOCHS)\n",
    "\n",
    "    best_state, best_loss = None, math.inf\n",
    "    out_dir = os.path.join(OUTPUT_BASE, f\"fold{fold}\"); os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        start_t = time.time(); model.train(); tot_loss = 0\n",
    "        print(f\"\\U0001f300 Fold {fold} | Epoch {epoch}/{EPOCHS}\")\n",
    "        for ids, msk, lbl in tqdm(train_loader, leave=False):\n",
    "            ids, msk, lbl = ids.to(DEVICE), msk.to(DEVICE), lbl.to(DEVICE)\n",
    "            optim.zero_grad(); loss = F.cross_entropy(model(ids, msk), lbl)\n",
    "            loss.backward(); torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0); optim.step()\n",
    "            tot_loss += loss.item()\n",
    "        scheduler.step()\n",
    "        print(f\"✅ Fold {fold} | Epoch {epoch} done | TrainLoss={tot_loss/len(train_loader):.4f} | Time={time.time()-start_t:.1f}s\")\n",
    "\n",
    "        model.eval(); val_loss, preds, yh = 0, [], []\n",
    "        with torch.no_grad():\n",
    "            for ids, msk, lbl in val_loader:\n",
    "                ids, msk, lbl = ids.to(DEVICE), msk.to(DEVICE), lbl.to(DEVICE)\n",
    "                out = model(ids, msk)\n",
    "                val_loss += F.cross_entropy(out, lbl, reduction='sum').item()\n",
    "                preds.append(out.argmax(1).cpu()); yh.append(lbl.cpu())\n",
    "        val_loss /= len(val_ds)\n",
    "        preds = torch.cat(preds).numpy(); y_true = torch.cat(yh).numpy()\n",
    "        print(f\"📊  ValLoss={val_loss:.4f}\")\n",
    "        if val_loss < best_loss:\n",
    "            best_loss, best_state = val_loss, copy.deepcopy(model.state_dict())\n",
    "\n",
    "    torch.save(best_state, os.path.join(out_dir, \"best_model.pt\"))\n",
    "    with open(os.path.join(out_dir, \"model_config.json\"), \"w\") as f:\n",
    "        json.dump({\"emb_dim\":EMB_DIM,\"n_layers\":N_LAYERS,\"n_heads\":N_HEADS,\"ff_dim\":FF_DIM,\"max_len\":MAX_LEN,\"vocab_size\":VOCAB_SIZE,\"pad_id\":PAD_ID,\"cls_id\":CLS_ID,\"label_map\":LABEL_MAP}, f, indent=2)\n",
    "    with open(os.path.join(out_dir, \"vocab.txt\"), \"w\") as f:\n",
    "        f.writelines([f\"{i}\\n\" for i in range(256)] + [\"[PAD]\\n\",\"[CLS]\\n\"])\n",
    "\n",
    "    model.load_state_dict(best_state); model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = []; y_true = []\n",
    "        for ids, msk, lbl in val_loader:\n",
    "            ids, msk = ids.to(DEVICE), msk.to(DEVICE)\n",
    "            logits.append(model(ids, msk).cpu()); y_true.append(lbl)\n",
    "    preds = torch.cat(logits).argmax(1).numpy(); y_true = torch.cat(y_true).numpy()\n",
    "\n",
    "    cm = confusion_matrix(y_true, preds, labels=list(range(len(cls_names))))\n",
    "    plt.figure(figsize=(7,6)); plt.imshow(cm, cmap='Blues'); plt.title(f\"Confusion Fold {fold}\")\n",
    "    plt.xticks(range(len(cls_names)), cls_names); plt.yticks(range(len(cls_names)), cls_names)\n",
    "    for r in range(len(cm)):\n",
    "        for c in range(len(cm)):\n",
    "            plt.text(c, r, cm[r,c], ha='center', va='center')\n",
    "    plt.xlabel('Predicted'); plt.ylabel('True'); plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_dir, \"confusion_fold.png\")); plt.close()\n",
    "\n",
    "    fold_val_losses.append((fold, best_loss))\n",
    "    for i, cls in enumerate(cls_names):\n",
    "        TP = cm[i,i]; FN = cm[i].sum()-TP; FP = cm[:,i].sum()-TP; TN = cm.sum()-TP-FN-FP\n",
    "        ACC  = (TP+TN)/cm.sum(); REC = TP/(TP+FN+1e-8); SPEC = TN/(TN+FP+1e-8); F1 = 2*TP/(2*TP+FP+FN+1e-8)\n",
    "        rows_all.append({\"fold\": fold, \"kelas\": cls, \"akurasi\": round(ACC,4), \"f1\": round(F1,4), \"recall\": round(REC,4), \"spesifisitas\": round(SPEC,4)})\n",
    "\n",
    "# Simpan metrik ke CSV akhir\n",
    "out_df = pd.DataFrame(rows_all)\n",
    "out_df.to_csv(os.path.join(OUTPUT_BASE, \"final_summary_perkelas.csv\"), index=False)\n",
    "\n",
    "# Ambil hanya fold terbaik berdasarkan val_loss terendah\n",
    "best_fold = sorted(fold_val_losses, key=lambda x: x[1])[0][0]\n",
    "out_df[out_df.fold == best_fold].to_csv(os.path.join(OUTPUT_BASE, \"final_summary_best_only.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09bec5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [06:56<00:00,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Evaluasi selesai. Hasil disimpan di: D:\\KULIAH\\TELKOM_UNIVERSITY\\SEMESTER_8\\TA\\TA_SKRIPSI_GUE\\HASIL_AKHIR_RECORD\\BEATS\\EVALUASI_DECODER_TEST\n"
     ]
    }
   ],
   "source": [
    "import os, json, torch, numpy as np, matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIG ===\n",
    "MODEL_PATH   = r\"D:\\KULIAH\\TELKOM_UNIVERSITY\\SEMESTER_8\\TA\\TA_SKRIPSI_GUE\\HASIL_TRAIN\\BEATS\\HASIL_DECODER\\HASIL_2\\fold4\\best_model.pt\"\n",
    "CONFIG_PATH  = r\"D:\\KULIAH\\TELKOM_UNIVERSITY\\SEMESTER_8\\TA\\TA_SKRIPSI_GUE\\HASIL_TRAIN\\BEATS\\HASIL_DECODER\\HASIL_2\\fold4\\model_config.json\"\n",
    "TEST_DIR     = r\"D:\\KULIAH\\TELKOM_UNIVERSITY\\SEMESTER_8\\TA\\TA_SKRIPSI_GUE\\DATA\\output_coba\\SPLIT_BEATS_NPY\\Beats_TEST\"\n",
    "OUTPUT_DIR   = r\"D:\\KULIAH\\TELKOM_UNIVERSITY\\SEMESTER_8\\TA\\TA_SKRIPSI_GUE\\HASIL_AKHIR_RECORD\\BEATS\\EVALUASI_DECODER_TEST\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# === Load config ===\n",
    "with open(CONFIG_PATH) as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "PAD_ID = config[\"pad_id\"]\n",
    "CLS_ID = config[\"cls_id\"]\n",
    "LABEL_MAP = config[\"label_map\"]\n",
    "IDX2LABEL = {v: k for k, v in LABEL_MAP.items()}\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === Define Decoder-Only Model ===\n",
    "class DecoderOnlyClassifier(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(config[\"vocab_size\"], config[\"emb_dim\"], padding_idx=PAD_ID)\n",
    "        self.pos_emb = nn.Parameter(torch.randn(1, config[\"max_len\"], config[\"emb_dim\"]))\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=config[\"emb_dim\"],\n",
    "            nhead=config[\"n_heads\"],\n",
    "            dim_feedforward=config[\"ff_dim\"],\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=config[\"n_layers\"])\n",
    "        self.fc = nn.Linear(config[\"emb_dim\"], len(config[\"label_map\"]))\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        x = self.token_emb(input_ids) + self.pos_emb[:, :input_ids.size(1), :]\n",
    "        memory = x.clone()\n",
    "        x = self.decoder(tgt=x, memory=memory, tgt_key_padding_mask=~attention_mask.bool())\n",
    "        x = (x * attention_mask.unsqueeze(-1)).sum(1) / attention_mask.sum(1, keepdim=True).clamp(min=1e-9)\n",
    "        return self.fc(x)\n",
    "\n",
    "# === Load Model ===\n",
    "model = DecoderOnlyClassifier(config).to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "# === Data Loader ===\n",
    "def signal_to_ids(sig):\n",
    "    norm = ((sig - sig.min()) / (sig.ptp() + 1e-8)) * 255\n",
    "    ids = [CLS_ID] + norm.astype(int).tolist()[:config[\"max_len\"] - 1]\n",
    "    mask = [1] * len(ids)\n",
    "    if len(ids) < config[\"max_len\"]:\n",
    "        pad_len = config[\"max_len\"] - len(ids)\n",
    "        ids += [PAD_ID] * pad_len\n",
    "        mask += [0] * pad_len\n",
    "    return torch.tensor(ids), torch.tensor(mask)\n",
    "\n",
    "X, M, Y = [], [], []\n",
    "for label in os.listdir(TEST_DIR):\n",
    "    label_path = os.path.join(TEST_DIR, label)\n",
    "    if not os.path.isdir(label_path): continue\n",
    "    for fname in os.listdir(label_path):\n",
    "        fpath = os.path.join(label_path, fname)\n",
    "        try:\n",
    "            sig = np.load(fpath)\n",
    "            ids, msk = signal_to_ids(sig)\n",
    "            X.append(ids); M.append(msk); Y.append(LABEL_MAP[label])\n",
    "        except:\n",
    "            print(f\"[WARNING] Failed to load {fpath}\")\n",
    "\n",
    "X = torch.stack(X)\n",
    "M = torch.stack(M)\n",
    "Y = torch.tensor(Y)\n",
    "\n",
    "# === Inference ===\n",
    "BATCH_SIZE = 64\n",
    "y_pred, y_true = [], []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, len(X), BATCH_SIZE)):\n",
    "        xb = X[i:i+BATCH_SIZE].to(DEVICE)\n",
    "        mb = M[i:i+BATCH_SIZE].to(DEVICE)\n",
    "        logits = model(xb, mb)\n",
    "        pred = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        y_pred.extend(pred)\n",
    "        y_true.extend(Y[i:i+BATCH_SIZE].numpy())\n",
    "\n",
    "# === Evaluation ===\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "rec = recall_score(y_true, y_pred, average='macro')\n",
    "f1  = f1_score(y_true, y_pred, average='macro')\n",
    "cm  = confusion_matrix(y_true, y_pred, labels=list(IDX2LABEL.keys()))\n",
    "\n",
    "# === Save Confusion Matrix ===\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.imshow(cm, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix - TEST SET\")\n",
    "plt.xticks(ticks=range(len(IDX2LABEL)), labels=IDX2LABEL.values())\n",
    "plt.yticks(ticks=range(len(IDX2LABEL)), labels=IDX2LABEL.values())\n",
    "for i in range(len(cm)):\n",
    "    for j in range(len(cm)):\n",
    "        plt.text(j, i, cm[i, j], ha='center', va='center')\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"confusion_test.png\"))\n",
    "plt.close()\n",
    "\n",
    "# === Save CSV Metrics Per Kelas ===\n",
    "rows = []\n",
    "for i, label in IDX2LABEL.items():\n",
    "    TP = cm[i,i]\n",
    "    FN = cm[i].sum() - TP\n",
    "    FP = cm[:,i].sum() - TP\n",
    "    TN = cm.sum() - TP - FN - FP\n",
    "    acc_cls  = (TP + TN) / cm.sum()\n",
    "    rec_cls  = TP / (TP + FN + 1e-8)\n",
    "    spec_cls = TN / (TN + FP + 1e-8)\n",
    "    f1_cls   = 2 * TP / (2 * TP + FP + FN + 1e-8)\n",
    "    rows.append({\n",
    "        \"kelas\": label,\n",
    "        \"akurasi\": round(acc_cls, 4),\n",
    "        \"recall\": round(rec_cls, 4),\n",
    "        \"f1\": round(f1_cls, 4),\n",
    "        \"spesifisitas\": round(spec_cls, 4)\n",
    "    })\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(os.path.join(OUTPUT_DIR, \"summary_test_metrics.csv\"), index=False)\n",
    "\n",
    "print(\"✅ Evaluasi selesai. Hasil disimpan di:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "802173ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/110 [00:00<?, ?it/s]c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:505: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\NestedTensorImpl.cpp:182.)\n",
      "  output = torch._nested_tensor_from_mask(\n",
      "100%|██████████| 110/110 [06:13<00:00,  3.40s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Evaluasi ENCODER test selesai. Semua file disimpan di: D:\\KULIAH\\TELKOM_UNIVERSITY\\SEMESTER_8\\TA\\TA_SKRIPSI_GUE\\HASIL_AKHIR_RECORD\\BEATS\\EVALUASI_ENCODER_TEST\n"
     ]
    }
   ],
   "source": [
    "import os, json, torch, numpy as np, matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === KONFIGURASI ===\n",
    "MODEL_PATH   = r\"D:\\KULIAH\\TELKOM_UNIVERSITY\\SEMESTER_8\\TA\\TA_SKRIPSI_GUE\\HASIL_TRAIN\\BEATS\\HASIL_ENCODER\\HASIL_4\\fold4\\best_model.pt\"\n",
    "CONFIG_PATH  = r\"D:\\KULIAH\\TELKOM_UNIVERSITY\\SEMESTER_8\\TA\\TA_SKRIPSI_GUE\\HASIL_TRAIN\\BEATS\\HASIL_ENCODER\\HASIL_4\\fold4\\model_config.json\"\n",
    "TEST_DIR     = r\"D:\\KULIAH\\TELKOM_UNIVERSITY\\SEMESTER_8\\TA\\TA_SKRIPSI_GUE\\DATA\\output_coba\\SPLIT_BEATS_NPY\\Beats_TEST\"\n",
    "OUTPUT_DIR   = r\"D:\\KULIAH\\TELKOM_UNIVERSITY\\SEMESTER_8\\TA\\TA_SKRIPSI_GUE\\HASIL_AKHIR_RECORD\\BEATS\\EVALUASI_ENCODER_TEST\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# === Load config ===\n",
    "with open(CONFIG_PATH) as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "PAD_ID = config[\"pad_id\"]\n",
    "CLS_ID = config[\"cls_id\"]\n",
    "LABEL_MAP = config[\"label_map\"]\n",
    "IDX2LABEL = {v: k for k, v in LABEL_MAP.items()}\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === Definisi Model Encoder ===\n",
    "class EncoderOnlyClassifier(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(config[\"vocab_size\"], config[\"emb_dim\"], padding_idx=PAD_ID)\n",
    "        self.pos_emb   = nn.Parameter(torch.zeros(1, config[\"max_len\"], config[\"emb_dim\"]))\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=config[\"emb_dim\"],\n",
    "            nhead=config[\"n_heads\"],\n",
    "            dim_feedforward=config[\"ff_dim\"],\n",
    "            dropout=0.1,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=config[\"n_layers\"])\n",
    "        self.fc = nn.Linear(config[\"emb_dim\"], len(config[\"label_map\"]))\n",
    "        nn.init.normal_(self.pos_emb, std=0.02)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        x = self.token_emb(input_ids) + self.pos_emb\n",
    "        x = self.encoder(x, src_key_padding_mask=~attention_mask.bool())\n",
    "        x = (x * attention_mask.unsqueeze(-1)).sum(1) / attention_mask.sum(1, keepdim=True).clamp(min=1e-8)\n",
    "        return self.fc(x)\n",
    "\n",
    "# === Load Model ===\n",
    "model = EncoderOnlyClassifier(config).to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "# === Fungsi Preprocessing Sinyal ===\n",
    "def signal_to_ids(sig):\n",
    "    norm = ((sig - sig.min()) / (sig.ptp() + 1e-8)) * 255\n",
    "    ids = [CLS_ID] + norm.astype(int).tolist()[:config[\"max_len\"] - 1]\n",
    "    mask = [1] * len(ids)\n",
    "    if len(ids) < config[\"max_len\"]:\n",
    "        pad_len = config[\"max_len\"] - len(ids)\n",
    "        ids += [PAD_ID] * pad_len\n",
    "        mask += [0] * pad_len\n",
    "    return torch.tensor(ids), torch.tensor(mask)\n",
    "\n",
    "# === Load Data Test ===\n",
    "X, M, Y = [], [], []\n",
    "for label in os.listdir(TEST_DIR):\n",
    "    label_path = os.path.join(TEST_DIR, label)\n",
    "    if not os.path.isdir(label_path): continue\n",
    "    for fname in os.listdir(label_path):\n",
    "        fpath = os.path.join(label_path, fname)\n",
    "        try:\n",
    "            sig = np.load(fpath)\n",
    "            ids, msk = signal_to_ids(sig)\n",
    "            X.append(ids); M.append(msk); Y.append(LABEL_MAP[label])\n",
    "        except:\n",
    "            print(f\"[WARNING] Failed to load {fpath}\")\n",
    "\n",
    "X = torch.stack(X)\n",
    "M = torch.stack(M)\n",
    "Y = torch.tensor(Y)\n",
    "\n",
    "# === Inference ===\n",
    "BATCH_SIZE = 64\n",
    "y_pred, y_true = [], []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, len(X), BATCH_SIZE)):\n",
    "        xb = X[i:i+BATCH_SIZE].to(DEVICE)\n",
    "        mb = M[i:i+BATCH_SIZE].to(DEVICE)\n",
    "        logits = model(xb, mb)\n",
    "        pred = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        y_pred.extend(pred)\n",
    "        y_true.extend(Y[i:i+BATCH_SIZE].numpy())\n",
    "\n",
    "# === Evaluasi Keseluruhan ===\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "rec = recall_score(y_true, y_pred, average='macro')\n",
    "f1  = f1_score(y_true, y_pred, average='macro')\n",
    "cm  = confusion_matrix(y_true, y_pred, labels=list(IDX2LABEL.keys()))\n",
    "\n",
    "# === Simpan Confusion Matrix PNG ===\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.imshow(cm, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix - TEST SET (Encoder)\")\n",
    "plt.xticks(ticks=range(len(IDX2LABEL)), labels=IDX2LABEL.values())\n",
    "plt.yticks(ticks=range(len(IDX2LABEL)), labels=IDX2LABEL.values())\n",
    "for i in range(len(cm)):\n",
    "    for j in range(len(cm)):\n",
    "        plt.text(j, i, cm[i, j], ha='center', va='center')\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"confusion_test_encoder.png\"))\n",
    "plt.close()\n",
    "\n",
    "# === Simpan CSV Metrik Per Kelas ===\n",
    "rows = []\n",
    "for i, label in IDX2LABEL.items():\n",
    "    TP = cm[i,i]\n",
    "    FN = cm[i].sum() - TP\n",
    "    FP = cm[:,i].sum() - TP\n",
    "    TN = cm.sum() - TP - FN - FP\n",
    "    acc_cls  = (TP + TN) / cm.sum()\n",
    "    rec_cls  = TP / (TP + FN + 1e-8)\n",
    "    spec_cls = TN / (TN + FP + 1e-8)\n",
    "    f1_cls   = 2 * TP / (2 * TP + FP + FN + 1e-8)\n",
    "    rows.append({\n",
    "        \"kelas\": label,\n",
    "        \"akurasi\": round(acc_cls, 4),\n",
    "        \"recall\": round(rec_cls, 4),\n",
    "        \"f1\": round(f1_cls, 4),\n",
    "        \"spesifisitas\": round(spec_cls, 4)\n",
    "    })\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(os.path.join(OUTPUT_DIR, \"summary_test_metrics_encoder.csv\"), index=False)\n",
    "\n",
    "print(\"✅ Evaluasi ENCODER test selesai. Semua file disimpan di:\", OUTPUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
